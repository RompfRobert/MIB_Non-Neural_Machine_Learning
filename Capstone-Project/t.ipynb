{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 19:33:57.934118: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-07 19:33:58.058243: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /app/lib\n",
      "2022-12-07 19:33:58.058263: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-07 19:33:59.611699: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /app/lib\n",
      "2022-12-07 19:33:59.611822: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /app/lib\n",
      "2022-12-07 19:33:59.611830: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35672 entries, 0 to 35671\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   DATUM        35672 non-null  datetime64[ns]\n",
      " 1   STATIONS_ID  35672 non-null  int64         \n",
      " 2   QN_4         35672 non-null  int64         \n",
      " 3   TT_TER       35672 non-null  float64       \n",
      " 4   RF_TER       35672 non-null  float64       \n",
      " 5   VGSL         35672 non-null  float64       \n",
      " 6   TS05         35672 non-null  float64       \n",
      " 7   BF10         35672 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(3)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "random_seed = 69\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "df = pd.read_csv('munster_hourly.csv', parse_dates=[\"DATUM\"])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35672 entries, 0 to 35671\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   DATUM   35672 non-null  datetime64[ns]\n",
      " 1   BF10    35672 non-null  float32       \n",
      "dtypes: datetime64[ns](1), float32(1)\n",
      "memory usage: 418.2 KB\n"
     ]
    }
   ],
   "source": [
    "df = df[[\"DATUM\", \"BF10\"]]\n",
    "df['BF10'] = df[\"BF10\"].astype('float32')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28537, 2)\n",
      "(3567, 2)\n",
      "(3568, 2)\n",
      "\n",
      "(28537,)\n",
      "(3567,)\n",
      "(3568,)\n"
     ]
    }
   ],
   "source": [
    "TIME_WINDOW=100\n",
    "FORECAST_DISTANCE=30\n",
    "\n",
    "targetcol = \"BF10\"\n",
    "targetcol_series = df[targetcol]\n",
    "\n",
    "X_train, X_else, targetcol_series_train, targetcol_series_else = train_test_split(df, \n",
    "                                   targetcol_series, \n",
    "                                   test_size=0.2, \n",
    "                                   shuffle=False)\n",
    "X_valid, X_test, targetcol_series_valid, targetcol_series_test = train_test_split(X_else, targetcol_series_else, test_size=0.5, shuffle=False)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n",
    "print()\n",
    "print(targetcol_series_train.shape)\n",
    "print(targetcol_series_valid.shape)\n",
    "print(targetcol_series_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SW8a9qT4rnrx"
   },
   "outputs": [],
   "source": [
    "def sliding_window_2D_from_df(df, targetcol_series, TIME_WINDOW, FORECAST_DISTANCE):\n",
    "    X_df = pd.concat([df.shift(i) for i in range(1,TIME_WINDOW+1)], axis=1)\\\n",
    "                      .iloc[TIME_WINDOW : len(df) - FORECAST_DISTANCE + 1]\n",
    "    X_df.columns = pd.MultiIndex.from_product([range(1,TIME_WINDOW+1), df.columns])\n",
    "    X_df.rename_axis([\"lag\", \"variable\"], axis=1, inplace=True)\n",
    "\n",
    "    y_series = targetcol_series.shift( -FORECAST_DISTANCE + 1 )\\\n",
    "                      .iloc[ TIME_WINDOW : len(df) - FORECAST_DISTANCE + 1 ]\n",
    "    return X_df, y_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vo2oH9NwDBTf"
   },
   "outputs": [],
   "source": [
    "def spot_check_sliding_window_2D(X_df, y_series, df, target_series, FORECAST_DISTANCE=1):\n",
    "    TIME_WINDOW = X_df.shape[1] // df.shape[1]\n",
    "    display(X_df.head(1).iloc[:,[*list(range(2*df.shape[1])), *list(range(-2*df.shape[1],0))]])\n",
    "    print(\"The following should be the first two lagged values:\")\n",
    "    display(df.iloc[:TIME_WINDOW].tail(2))\n",
    "    print(\"The following should be the last two lagged values:\")\n",
    "    display(df.head(2))\n",
    "\n",
    "    print(f\"\\nThe target (FORECAST_DISTANCE={FORECAST_DISTANCE}):\")\n",
    "    display(y_series.iloc[:10].to_frame().T)\n",
    "    print(f\"The actual values from the end of the first time window (TIME_WINDOW={TIME_WINDOW}):\")\n",
    "    display(target_series.iloc[TIME_WINDOW:].iloc[:FORECAST_DISTANCE+9].to_frame().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hebBoeb2C9RC"
   },
   "outputs": [],
   "source": [
    "X_df_train, y_train = sliding_window_2D_from_df(X_train, targetcol_series_train, TIME_WINDOW, FORECAST_DISTANCE)\n",
    "X_df_valid, y_valid = sliding_window_2D_from_df(X_valid, targetcol_series_valid, TIME_WINDOW, FORECAST_DISTANCE)\n",
    "X_df_test, y_test = sliding_window_2D_from_df(X_test, targetcol_series_test, TIME_WINDOW, FORECAST_DISTANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>lag</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">99</th>\n",
       "      <th colspan=\"2\" halign=\"left\">100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1991-02-03 07:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-02 21:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-01-01 14:00:00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1991-01-01 07:00:00</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "lag                      1                         2          \\\n",
       "variable               DATUM  BF10               DATUM  BF10   \n",
       "100      1991-02-03 07:00:00  97.0 1991-02-02 21:00:00  97.0   \n",
       "\n",
       "lag                      99                         100         \n",
       "variable               DATUM   BF10               DATUM   BF10  \n",
       "100      1991-01-01 14:00:00  102.0 1991-01-01 07:00:00  102.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following should be the first two lagged values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1991-02-02 21:00:00</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1991-02-03 07:00:00</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATUM  BF10\n",
       "98 1991-02-02 21:00:00  97.0\n",
       "99 1991-02-03 07:00:00  97.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following should be the last two lagged values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991-01-01 07:00:00</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991-01-01 14:00:00</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                DATUM   BF10\n",
       "0 1991-01-01 07:00:00  102.0\n",
       "1 1991-01-01 14:00:00  102.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The target (FORECAST_DISTANCE=30):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BF10</th>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       100   101   102    103    104    105    106    107    108    109\n",
       "BF10  99.0  99.0  99.0  100.0  100.0  100.0  106.0  106.0  106.0  102.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual values from the end of the first time window (TIME_WINDOW=100):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>...</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BF10</th>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       100   101   102   103   104   105   106   107   108   109  ...   129  \\\n",
       "BF10  97.0  97.0  97.0  97.0  97.0  96.0  96.0  96.0  96.0  96.0  ...  99.0   \n",
       "\n",
       "       130   131    132    133    134    135    136    137    138  \n",
       "BF10  99.0  99.0  100.0  100.0  100.0  106.0  106.0  106.0  102.0  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_check_sliding_window_2D(X_df_train, y_train, X_train, targetcol_series_train, FORECAST_DISTANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>lag</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">3</th>\n",
       "      <th colspan=\"2\" halign=\"left\">4</th>\n",
       "      <th colspan=\"2\" halign=\"left\">5</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">96</th>\n",
       "      <th colspan=\"2\" halign=\"left\">97</th>\n",
       "      <th colspan=\"2\" halign=\"left\">98</th>\n",
       "      <th colspan=\"2\" halign=\"left\">99</th>\n",
       "      <th colspan=\"2\" halign=\"left\">100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "      <th>...</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>BF10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1991-02-03 07:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-02 21:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-02 14:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-02 07:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-01 21:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1991-01-02 14:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-02 07:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-01 21:00:00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1991-01-01 14:00:00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1991-01-01 07:00:00</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1991-02-03 14:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-03 07:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-02 21:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-02 14:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-02 07:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1991-01-02 21:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-02 14:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-02 07:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-01 21:00:00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1991-01-01 14:00:00</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1991-02-03 21:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-03 14:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-03 07:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-02 21:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-02 14:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1991-01-03 07:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-02 21:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-02 14:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-02 07:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-01 21:00:00</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1991-02-04 07:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-03 21:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-03 14:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-03 07:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-02 21:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1991-01-03 14:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-03 07:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-02 21:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-02 14:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-02 07:00:00</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1991-02-04 14:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-04 07:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-03 21:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-03 14:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1991-02-03 07:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1991-01-03 21:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-03 14:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-03 07:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-02 21:00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1991-01-02 14:00:00</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28503</th>\n",
       "      <td>2017-01-04 18:00:00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2017-01-04 12:00:00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2017-01-04 06:00:00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2017-01-03 18:00:00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2017-01-03 12:00:00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-12-04 06:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2016-12-03 18:00:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2016-12-03 12:00:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2016-12-03 06:00:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2016-12-02 18:00:00</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28504</th>\n",
       "      <td>2017-01-05 06:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2017-01-04 18:00:00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2017-01-04 12:00:00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2017-01-04 06:00:00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2017-01-03 18:00:00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-12-04 12:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2016-12-04 06:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2016-12-03 18:00:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2016-12-03 12:00:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2016-12-03 06:00:00</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28505</th>\n",
       "      <td>2017-01-05 12:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2017-01-05 06:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2017-01-04 18:00:00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2017-01-04 12:00:00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2017-01-04 06:00:00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-12-04 18:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2016-12-04 12:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2016-12-04 06:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2016-12-03 18:00:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2016-12-03 12:00:00</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28506</th>\n",
       "      <td>2017-01-05 18:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2017-01-05 12:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2017-01-05 06:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2017-01-04 18:00:00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2017-01-04 12:00:00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-12-05 06:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2016-12-04 18:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2016-12-04 12:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2016-12-04 06:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2016-12-03 18:00:00</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28507</th>\n",
       "      <td>2017-01-06 06:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2017-01-05 18:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2017-01-05 12:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2017-01-05 06:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2017-01-04 18:00:00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-12-05 12:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2016-12-05 06:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2016-12-04 18:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2016-12-04 12:00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2016-12-04 06:00:00</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28408 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "lag                      1                          2           \\\n",
       "variable               DATUM   BF10               DATUM   BF10   \n",
       "100      1991-02-03 07:00:00   97.0 1991-02-02 21:00:00   97.0   \n",
       "101      1991-02-03 14:00:00   97.0 1991-02-03 07:00:00   97.0   \n",
       "102      1991-02-03 21:00:00   97.0 1991-02-03 14:00:00   97.0   \n",
       "103      1991-02-04 07:00:00   97.0 1991-02-03 21:00:00   97.0   \n",
       "104      1991-02-04 14:00:00   97.0 1991-02-04 07:00:00   97.0   \n",
       "...                      ...    ...                 ...    ...   \n",
       "28503    2017-01-04 18:00:00  109.0 2017-01-04 12:00:00  109.0   \n",
       "28504    2017-01-05 06:00:00  104.0 2017-01-04 18:00:00  109.0   \n",
       "28505    2017-01-05 12:00:00  104.0 2017-01-05 06:00:00  104.0   \n",
       "28506    2017-01-05 18:00:00  104.0 2017-01-05 12:00:00  104.0   \n",
       "28507    2017-01-06 06:00:00  104.0 2017-01-05 18:00:00  104.0   \n",
       "\n",
       "lag                      3                          4           \\\n",
       "variable               DATUM   BF10               DATUM   BF10   \n",
       "100      1991-02-02 14:00:00   97.0 1991-02-02 07:00:00   97.0   \n",
       "101      1991-02-02 21:00:00   97.0 1991-02-02 14:00:00   97.0   \n",
       "102      1991-02-03 07:00:00   97.0 1991-02-02 21:00:00   97.0   \n",
       "103      1991-02-03 14:00:00   97.0 1991-02-03 07:00:00   97.0   \n",
       "104      1991-02-03 21:00:00   97.0 1991-02-03 14:00:00   97.0   \n",
       "...                      ...    ...                 ...    ...   \n",
       "28503    2017-01-04 06:00:00  109.0 2017-01-03 18:00:00  102.0   \n",
       "28504    2017-01-04 12:00:00  109.0 2017-01-04 06:00:00  109.0   \n",
       "28505    2017-01-04 18:00:00  109.0 2017-01-04 12:00:00  109.0   \n",
       "28506    2017-01-05 06:00:00  104.0 2017-01-04 18:00:00  109.0   \n",
       "28507    2017-01-05 12:00:00  104.0 2017-01-05 06:00:00  104.0   \n",
       "\n",
       "lag                      5           ...                 96          \\\n",
       "variable               DATUM   BF10  ...               DATUM   BF10   \n",
       "100      1991-02-01 21:00:00   97.0  ... 1991-01-02 14:00:00  110.0   \n",
       "101      1991-02-02 07:00:00   97.0  ... 1991-01-02 21:00:00  110.0   \n",
       "102      1991-02-02 14:00:00   97.0  ... 1991-01-03 07:00:00  110.0   \n",
       "103      1991-02-02 21:00:00   97.0  ... 1991-01-03 14:00:00  110.0   \n",
       "104      1991-02-03 07:00:00   97.0  ... 1991-01-03 21:00:00  110.0   \n",
       "...                      ...    ...  ...                 ...    ...   \n",
       "28503    2017-01-03 12:00:00  102.0  ... 2016-12-04 06:00:00   97.0   \n",
       "28504    2017-01-03 18:00:00  102.0  ... 2016-12-04 12:00:00   97.0   \n",
       "28505    2017-01-04 06:00:00  109.0  ... 2016-12-04 18:00:00   97.0   \n",
       "28506    2017-01-04 12:00:00  109.0  ... 2016-12-05 06:00:00   97.0   \n",
       "28507    2017-01-04 18:00:00  109.0  ... 2016-12-05 12:00:00   97.0   \n",
       "\n",
       "lag                      97                         98          \\\n",
       "variable               DATUM   BF10               DATUM   BF10   \n",
       "100      1991-01-02 07:00:00  110.0 1991-01-01 21:00:00  102.0   \n",
       "101      1991-01-02 14:00:00  110.0 1991-01-02 07:00:00  110.0   \n",
       "102      1991-01-02 21:00:00  110.0 1991-01-02 14:00:00  110.0   \n",
       "103      1991-01-03 07:00:00  110.0 1991-01-02 21:00:00  110.0   \n",
       "104      1991-01-03 14:00:00  110.0 1991-01-03 07:00:00  110.0   \n",
       "...                      ...    ...                 ...    ...   \n",
       "28503    2016-12-03 18:00:00   98.0 2016-12-03 12:00:00   98.0   \n",
       "28504    2016-12-04 06:00:00   97.0 2016-12-03 18:00:00   98.0   \n",
       "28505    2016-12-04 12:00:00   97.0 2016-12-04 06:00:00   97.0   \n",
       "28506    2016-12-04 18:00:00   97.0 2016-12-04 12:00:00   97.0   \n",
       "28507    2016-12-05 06:00:00   97.0 2016-12-04 18:00:00   97.0   \n",
       "\n",
       "lag                      99                         100         \n",
       "variable               DATUM   BF10               DATUM   BF10  \n",
       "100      1991-01-01 14:00:00  102.0 1991-01-01 07:00:00  102.0  \n",
       "101      1991-01-01 21:00:00  102.0 1991-01-01 14:00:00  102.0  \n",
       "102      1991-01-02 07:00:00  110.0 1991-01-01 21:00:00  102.0  \n",
       "103      1991-01-02 14:00:00  110.0 1991-01-02 07:00:00  110.0  \n",
       "104      1991-01-02 21:00:00  110.0 1991-01-02 14:00:00  110.0  \n",
       "...                      ...    ...                 ...    ...  \n",
       "28503    2016-12-03 06:00:00   98.0 2016-12-02 18:00:00   98.0  \n",
       "28504    2016-12-03 12:00:00   98.0 2016-12-03 06:00:00   98.0  \n",
       "28505    2016-12-03 18:00:00   98.0 2016-12-03 12:00:00   98.0  \n",
       "28506    2016-12-04 06:00:00   97.0 2016-12-03 18:00:00   98.0  \n",
       "28507    2016-12-04 12:00:00   97.0 2016-12-04 06:00:00   97.0  \n",
       "\n",
       "[28408 rows x 200 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## where we are at...: something we can feed into generic models (e.g., feedfwd NN's, sklearn models like RF...)\n",
    "X_df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Inl4dYWbCxA3"
   },
   "outputs": [],
   "source": [
    "def rolled_X_from_2D_sliding_window_df(X_df, timesteps):\n",
    "    X_rolled = X_df.values.reshape(X_df.shape[0], timesteps, -1)\n",
    "    return X_rolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7w9x5CWGr0j9"
   },
   "outputs": [],
   "source": [
    "X_rolled_train = rolled_X_from_2D_sliding_window_df(X_df_train, TIME_WINDOW)\n",
    "X_rolled_valid = rolled_X_from_2D_sliding_window_df(X_df_valid, TIME_WINDOW)\n",
    "X_rolled_test = rolled_X_from_2D_sliding_window_df(X_df_test, TIME_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIx4IUhstAb8",
    "outputId": "f9cd004f-e67c-4e4f-847e-a3474ad6ff21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28408,)\n",
      "(28408, 200)\n",
      "(28408, 100, 2)\n",
      "\n",
      "(3439,)\n",
      "(3439, 200)\n",
      "(3439, 100, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_df_train.shape)\n",
    "print(X_rolled_train.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "print(y_test.shape)\n",
    "print(X_df_test.shape)\n",
    "print(X_rolled_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28408, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "## Quick data prep that is intuitively a good starting point\n",
    "\n",
    "VALID_AND_TEST_SIZE = 0.1\n",
    "TIME_WINDOW=100\n",
    "FORECAST_DISTANCE=30\n",
    "\n",
    "targetcol = \"BF10\"\n",
    "targetcol_series = df[targetcol]\n",
    "\n",
    "## train valid test split\n",
    "X_train, X_else, targetcol_series_train, targetcol_series_else = train_test_split(df[[\"BF10\"]], \n",
    "                                   targetcol_series, \n",
    "                                   test_size=VALID_AND_TEST_SIZE*2, \n",
    "                                   shuffle=False)\n",
    "X_valid, X_test, targetcol_series_valid, targetcol_series_test = train_test_split(X_else, targetcol_series_else, test_size=0.5, shuffle=False)\n",
    "\n",
    "## sliding window\n",
    "X_df_train, y_train = sliding_window_2D_from_df(X_train, targetcol_series_train, TIME_WINDOW, FORECAST_DISTANCE)\n",
    "X_df_valid, y_valid = sliding_window_2D_from_df(X_valid, targetcol_series_valid, TIME_WINDOW, FORECAST_DISTANCE)\n",
    "X_df_test, y_test = sliding_window_2D_from_df(X_test, targetcol_series_test, TIME_WINDOW, FORECAST_DISTANCE)\n",
    "\n",
    "## for lstm\n",
    "X_rolled_train = rolled_X_from_2D_sliding_window_df(X_df_train, TIME_WINDOW)\n",
    "X_rolled_valid = rolled_X_from_2D_sliding_window_df(X_df_valid, TIME_WINDOW)\n",
    "X_rolled_test = rolled_X_from_2D_sliding_window_df(X_df_test, TIME_WINDOW)\n",
    "\n",
    "print(X_rolled_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras import backend as be\n",
    "import tensorflow as tf\n",
    "\n",
    "## we use 10 samples\n",
    "## and 4 units (hidden state is 4-long for each time step)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "be.clear_session()\n",
    "input_layer = X_rolled_train[:10]\n",
    "\n",
    "whole_seq_output, final_memory_state, final_carry_state =  LSTM(4, return_sequences=True, return_state=True)(input_layer)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "be.clear_session()\n",
    "whole_seq_output2 =  LSTM(4, return_sequences=True, return_state=False)(input_layer)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "be.clear_session()\n",
    "out_last =  LSTM(4, return_sequences=False, return_state=False)(input_layer)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "be.clear_session()\n",
    "whole_seq_output3, final_memory_state3, final_carry_state3 =  LSTM(4, return_sequences=False, return_state=True)(input_layer)\n",
    "\n",
    "\n",
    "print(\"return_sequences=True, return_state=True\")\n",
    "print(whole_seq_output.shape)\n",
    "print(final_memory_state.shape)\n",
    "print(final_carry_state.shape)\n",
    "\n",
    "print()\n",
    "print(\"return_sequences=True, return_state=False\")\n",
    "print(whole_seq_output2.shape)\n",
    "\n",
    "print()\n",
    "print(\"return_sequences=False, return_state=False\")\n",
    "print(out_last.shape)\n",
    "\n",
    "print()\n",
    "print(\"return_sequences=False, return_state=True\")\n",
    "print(whole_seq_output3.shape)\n",
    "print(final_memory_state3.shape)\n",
    "print(final_carry_state3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:27:37.313391Z",
     "start_time": "2020-05-27T17:27:37.310265Z"
    },
    "id": "2RGULvUJnU0s",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 300\n",
    "LEARNING_RATE = 0.1\n",
    "N_CELLS = 50\n",
    "KERNEL = 'GlorotNormal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hr6iPDD7iwFs",
    "outputId": "a556e975-03ea-48ef-e2de-edadddaa02bf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input\n",
    "from tensorflow.keras import backend as be\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "## number of input variables: the final dimension in the 3D prepared data (index 2)\n",
    "column_count=X_rolled_train.shape[2]\n",
    "\n",
    "be.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(N_CELLS, activation='tanh', kernel_initializer=KERNEL, return_sequences=True, input_shape = (TIME_WINDOW, column_count)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = N_CELLS, activation='tanh', kernel_initializer=KERNEL, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = N_CELLS, activation='tanh', kernel_initializer=KERNEL, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = N_CELLS))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "## remember, we're doing regression, so choose loss (and output layer) accordingly!\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:47:20.013112Z",
     "start_time": "2020-05-27T17:27:39.376598Z"
    },
    "id": "Z3wD1ZkenU0s"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=X_rolled_train,\n",
    "                    y=y_train, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    validation_data=(X_rolled_valid,y_valid), \n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=1, \n",
    "                    shuffle=False,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:47:20.785872Z",
     "start_time": "2020-05-27T17:47:20.418603Z"
    },
    "id": "5TyllsD8nU0s"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:47:25.916627Z",
     "start_time": "2020-05-27T17:47:21.221977Z"
    },
    "id": "CONx5MLFnU0t"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_rolled_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:47:26.638783Z",
     "start_time": "2020-05-27T17:47:26.262070Z"
    },
    "id": "h5yl0egInU0t"
   },
   "outputs": [],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# Function to create model, required for KerasRegressor\n",
    "def create_model(optimizer='adam', init='glorot_uniform', activation='tanh' ):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation=activation, kernel_initializer=init, return_sequences=True, input_shape = (TIME_WINDOW, column_count)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units = 50, activation=activation, kernel_initializer=init, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units = 50, activation=activation, kernel_initializer=init, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units = 50))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(units = 1))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return model\n",
    " \n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "X = X_rolled_train\n",
    "Y = y_train\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['rmsprop', 'Adamax', 'SGD']\n",
    "epochs = [10,20,40]\n",
    "batches = [16, 32, 100]\n",
    "activation = ['tanh', 'relu']\n",
    "\n",
    "param_grid = dict(optimizer=optimizers, epochs=[4], batch_size=batches, activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, verbose=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d25534eb59e448589a4a5aad87c49c13e3bdddce89d2db63f381969f98310c1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
